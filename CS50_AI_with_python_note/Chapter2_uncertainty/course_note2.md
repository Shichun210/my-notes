# Uncertainty

## 序

比较困难的一课，从视频课程开始，就听得似是而非。整理笔记的过程中才理解了一些知识点和烦人的公式。

## 为什么需要概率

在现实世界中，很多情况都是 **不确定的**，例如：

- 下雨的概率是 30%。
- 某人患某种病的概率是 0.1%。
- 某人有该病的症状时，真实患病的概率是多少？

为了处理这种不确定性，AI 中引入了 **概率模型**。

------

## 基本概率定义

- **随机变量 (Random Variable)**
   表示一个可能取值的事件，例如：

  - 天气：{晴天, 雨天}
  - 基因数目：{0, 1, 2}

- **概率分布 (Probability Distribution)**
   一个变量所有可能取值的概率之和为 1：
  $$
  \sum_{x \in X} P(x) = 1
  $$

例子：
$$
P(\text{Weather=Sunny}) = 0.7, \quad P(\text{Weather=Rainy}) = 0.3
$$

------

## 联合概率 (Joint Probability)

- 表示多个变量同时取值的概率。
   例如：
  $$
  P(\text{Toothache} = \text{true}, \text{Cavity} = \text{true})
  $$

- **规则**：所有组合的概率相加应为 1。
  $$
  \sum_{x,y} P(X=x, Y=y) = 1
  $$

例子：如果一个人有 **牙痛** (Toothache) 和 **蛀牙** (Cavity) 的关系应该为：$P(X = x_i) = \sum_j P(X = x_i \mid Y = y_j) \cdot P(Y = y_j)$

- $P(\text{Toothache}, \text{Cavity}) = 0.04$
- $P(\text{Toothache}, \neg \text{Cavity}) = 0.06$
- $P(\neg \text{Toothache}, \text{Cavity}) = 0.1$
- $P(\neg \text{Toothache}, \neg \text{Cavity}) = 0.8$
- …（所有组合加起来 = 1）

------

## 归一化 (Normalization)

概率计算过程中，可能得到一个“未归一化的概率”，此时需要重新缩放，使它们相加等于 1。

公式：
$$
P'(x) = \frac{P(x)}{\sum_x P(x)}
$$
例子：

- 计算得到结果 $\{A: 2, B: 3\}$，未归一化。

- 总和 = 5。

- 归一化后：
  $$
  P(A) = \frac{2}{5} = 0.4, \quad P(B) = \frac{3}{5} = 0.6
  $$

------

## 条件概率与贝叶斯公式

- **条件概率**：
  $$
  P(A|B) = \frac{P(A, B)}{P(B)}
  $$
  读作：“在 B 发生的前提下，A 发生的概率”。

  比如，已知总共有10个球，其中4个是红球，6个是白球，又知道4个红球里面有2个是大球。

  那么我们想要知道已知抽到是红球的情况下，是大球的概率是多少？
  $$
  P(大球|红球) = \frac{P(大球, 红球)}{P(红球)} = \frac{2/10}{4/10} = 0.5
  $$
  
  也就是说已经知道了某个条件，就把概率限定到只有那个条件发生的世界
  
  
  
- **贝叶斯公式**：
  贝叶斯公式是根据条件概率公式推导：
  $$
  P(A,B) = {P(A|B) \cdot}{P(B)} \\
  P(A,B) = {P(B|A) \cdot}{P(A)} \\
  {P(A|B) \cdot}{P(B)} = {P(B|A) \cdot}{P(A)}
  $$
  $$
  P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
  $$

例子：疾病诊断

- 某病在总体中的概率：$P(\text{Disease}) = 0.01$
- 有病的人检测阳性的概率：$P(\text{Positive}|\text{Disease}) = 0.9$
- 没病的人误检阳性的概率：$P(\text{Positive}|\neg \text{Disease}) = 0.1$

问题：检测阳性时，患病的概率是多少？
$$
P(\text{Disease}|\text{Positive}) = \frac{0.9 \cdot 0.01}{0.9 \cdot 0.01 + 0.1 \cdot 0.99} \approx 0.083
$$
👉 说明即使检测阳性，真实患病概率只有 **8.3%**，并非直觉上的 90%。

------

## 贝叶斯网络 (Bayesian Network)

- 一种用 **有向无环图 (DAG)** 表示因果关系的模型。
- 节点：随机变量
- 边：依赖关系

例子：

- `Cavity → Toothache`
- `Cavity → Catch`

**优势**：避免存储庞大的联合概率表，通过条件概率表 (CPT) 来简化表示。

------

## 推理 (Inference) 方法

### 枚举 (Enumeration)

- 列出所有可能组合，计算目标概率。
- 缺点：组合数随变量数指数增长。

### 采样 (Sampling)

- 随机生成样本，估计概率分布。
- 更高效，近似解。

### 似然加权 (Likelihood Weighting)

- 改进的采样方法，给“已知条件”赋予权重，提高效率。
- 在条件概率场景下特别有用。

------

## 马尔可夫模型 (Markov Models)

- **假设**：未来只依赖于现在，与过去无关（马尔可夫性）。
  $$
  P(X_t | X_{t-1}, X_{t-2}, \dots) = P(X_t | X_{t-1})
  $$

- 应用：天气预测、语音识别、自然语言处理。

例子：
$$
P(\text{Sunny}_{t+1}|\text{Sunny}_t) = 0.9, \quad P(\text{Rainy}_{t+1}|\text{Sunny}_t) = 0.1
$$

------

## 总结

1. **概率分布**：用于描述不确定性。
2. **联合概率 & 归一化**：组合多个变量，保持总和为 1。
3. **条件概率 & 贝叶斯公式**：核心工具，用于推理。
4. **贝叶斯网络**：高效表示因果依赖。
5. **推理方法**：枚举 → 采样 → 似然加权。
6. **马尔可夫模型**：用于时间序列预测。

---

## 课后思考

这节课的内容涉及概率论的知识。比较抽象，有点不好理解，而且涉及了许多公式更是有点劝退。反复地看课后笔记，然后举通俗的例子，才算基本理解了这堂课的知识点。然而课后的作业也不简单，烧脑程度超过前两堂课。