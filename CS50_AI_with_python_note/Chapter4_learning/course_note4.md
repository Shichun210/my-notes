# Learning

这一讲主要讲机器学习的基础。以前写代码，我们习惯是一步步写死规则。但机器学习的思路不一样：我们不给规则，而是给它数据，让计算机自己去“摸规律”。这个转变挺神奇的，相当于从“教它做事”变成“让它学会自己做事”。

------

## 📘 监督学习

所谓监督学习，就是“有老师教”的模式：数据集里每条数据都有输入和对应的正确答案（标签）。模型的任务就是学会从输入预测出这个标签。

> 比如：输入是湿度和气压，输出是“下雨 / 不下雨”。我们拿以前的天气数据训练模型，模型学到规律之后，新的湿度和气压数据就能让它预测是不是下雨。

------

### 🎯 分类问题

分类就是最典型的监督学习。输入一些数据，输出一个类别。像天气预测、真假钞票识别、图片里的猫狗识别，都是分类问题。

---

#### 最近邻 (Nearest Neighbor)

最简单粗暴的想法是：新点长得像哪个邻居，就分到那个类。比如白点离蓝点最近，就预测为蓝色。

问题在于：有时候最近的那个点不具有代表性。比如最近的是红色，但周围大多数都是蓝色。那预测成红色可能就不太靠谱。

于是有了 **k-近邻 (k-NN)**：不只看一个邻居，而是看最近的 k 个。用投票的方式决定类别。比如 k=3，如果三个邻居里两个是蓝色，一个是红色，那就预测蓝色。这比单个邻居靠谱多了。

> [!warning]
>
> k-NN 的缺点是计算开销大。每次预测都要和所有数据点算距离，数据量大时就比较慢。
>
> > [!tip]
> >
> > 可以通过使用能够更快地找到邻居的数据结构或修剪不相关的观测值来加快计算速度。

---

#### 感知机 (Perceptron)

相比“最近邻”这种看单点的策略，感知机更像是把数据当成整体来对待。它会尝试找到一条**决策边界**（在二维就是一条直线，在高维就是超平面），然后通过判断新数据点落在边界的哪一侧，来决定它属于哪一类。

当然，真实数据通常比较“乱”，不可能完美地分开两类。感知机的做法是找一条尽量合理的边界：大部分情况下能分类正确，但偶尔会有误差。

训练的方式也挺直观：预测错了就调一下权重，预测对了就不动。学习率 α 控制了调整的幅度。

##### 🧮 数学形式

假设我们用湿度和气压来预测是否下雨，记为 $x_1$（湿度）、$x_2$（气压）。感知机的假设函数可以写成一个线性表达式：
$$
h(x_1, x_2) = 
\begin{cases}
1 & \text{如果 } w_0 + w_1 x_1 + w_2 x_2 \geq 0 \quad （预测下雨） \\
0 & \text{否则（预测不下雨）}
\end{cases}
$$
这里：

- $w_0$ 是偏置（常数项），
- $w_1, w_2$ 是权重（表示湿度和气压对预测的影响）。

用向量形式更简洁：

- 权重向量 $w = (w_0, w_1, w_2)$

- 输入向量 $x = (1, x_1, x_2)$

- 判别式就是两者的点积：
  $$
  w \cdot x = w_0 + w_1 x_1 + w_2 x_2
  $$

> [!note]
>
> ![决策边界](https://cs50.harvard.edu/ai/notes/4/decisionboundary.png)
>
> 权重W1和W2的比率，确定这条线的倾斜度，W0则保持斜率的情况下，上下平行移动。
>
> > [!tip]
> >
> > 也就是说，通过样本的学习，我们可以不断地调整W0，W1和W2，让这根线更准确地划分红色和蓝色(下雨和不下雨)。后面再输入数据，我们就可以比较准确地预测出输入是红点还是蓝点。

> [!important]
>
> 感知机的核心就是**不断更新权重**。
>
> - 如果预测正确 → 权重不变；
> - 如果预测错了 → 按照错误方向调整权重，修正分界线；
> - 调整幅度由学习率 $\alpha$ 控制。
>
> 公式上，更新规则大致是：
> $$
> w \leftarrow w + \alpha \cdot (y - \hat{y}) \cdot x
> $$
> 其中 $y$ 是真实标签，$\hat{y}$ 是预测结果。
>  如果预测对了，两者相等，不更新；预测错了，就往正确的方向推一把。

##### ⚖️ 硬阈值 vs 软阈值

感知机的输出只有 0 或 1，是一个**硬阈值函数**。
 问题在于，它没法表达“不确定性”。比如模型也许“70% 确定要下雨”，但感知机只能给出“下雨”或“不下雨”。

为了解决这个问题，可以换成**逻辑回归**，用一个**软阈值函数**把输出压缩到 0~1 之间。这样，数值本身就可以解释为“下雨的概率”。

#### 支持向量机 (SVM)

SVM 的核心想法是：不是随便画条线，而是画一条“最安全”的线。也就是最大化两边数据点的间隔。这样即使有点小波动，新数据也不容易被错分。

更厉害的是，SVM 不只会画直线，还能通过核函数处理非线性边界。比如两个类别分别分布成圆圈和圆环，用线分不开，但用 SVM 就能搞定。

一句话总结分类的几种方法：

- 最近邻：找朋友，看你最像谁。
- 感知机：画一条分界线。
- SVM：画一条最安全的分界线。

------

## 📈 回归

回归和分类的区别在于：它预测的是一个连续值。

举个例子，公司想知道广告花费多少能带来多少销售额。这个问题不是“是/否”，而是一个实数预测。

所以回归的目标是拟合一条趋势线，能根据输入预测出合理的输出。

------

## ⚖️ 损失函数

训练模型时，我们得有办法衡量“预测得好不好”。这就是损失函数。

- 分类常用 0-1 损失：预测对了就是 0，错了就是 1。
- 回归常用 L1 和 L2 损失：
  - L1 = 预测值和真实值的差的绝对值
  - L2 = 差的平方（对异常值更敏感）

损失函数就像打分，越小越好。

------

## 🌀 过拟合与正则化

### 过拟合

学过头了。模型在训练集上表现得完美，但新数据一来就惨不忍睹。相当于“死记硬背”而没有“举一反三”。

>![过度拟合](https://cs50.harvard.edu/ai/notes/4/overfitting.png)
>
>

### 正则化

解决办法之一是：别让模型太复杂。在损失函数里加一项“复杂度惩罚”：

```
cost(h) = loss(h) + λ * complexity(h)
```

λ 越大，就越倾向于选择简单的模型。简单模型虽然没法 100% 记住训练数据，但泛化能力更强。

### 模型评估

常用交叉验证（Cross Validation）：把数据分成训练集和测试集，或者做 k 折交叉验证，多次训练/测试取平均。这样更公平地评估模型。

------

## ⚙️ scikit-learn 实战

scikit-learn 是 Python 的机器学习库，最大的优点就是：换模型就只改一行代码。

比如钞票真伪识别任务，输入是钞票的 4 个特征，输出是真 / 假。我们可以用 KNN、SVM、感知机、朴素贝叶斯，代码结构完全一样，只要改模型的初始化。

这让我体会到，实际应用里“多试几个模型”并不是难事，而是推荐的工作流程。

> 在课后作业里面我会介绍scikit-learn库的实际使用

------

## 🤖 强化学习

和监督学习不同，强化学习没有“标准答案”。它学的是如何做决策，靠的是奖励和惩罚。

流程是这样的：

1. 环境给你一个状态；
2. 你做一个动作；
3. 环境给你新的状态和奖励（可能是 +1，也可能是 -1）；
4. 你根据奖励来调整下次的行为。

典型例子是机器人学走路：走一步没摔倒 +1，摔倒 -1。训练久了，它自然就学会走了。

> 强化学习和人类学习最像，通过试错、奖励来积累经验

### 马尔可夫决策过程 (MDP)

形式化来看，强化学习可以表示为：

- 状态集合 S
- 动作集合 A
- 状态转移模型 P(s’|s,a)
- 奖励函数 R(s,a,s’)

### Q-Learning

**Q-Learning 是强化学习的代表算法**。它维护一个表 Q(s,a)，表示“在状态 s 下采取动作 a 的价值”。

更新公式是：

```
Q(s,a) ← Q(s,a) + α * (r + γ * max Q(s’,a’) - Q(s,a))
```

意思是：当前价值等于旧价值，加上“学习率 * （奖励 + 未来最优价值 - 旧价值）”。
 这样奖励会慢慢往前传递，让前面的状态也学到经验。

> [!note]
>
> 随着学习的进行，每一步的决策都会从未来的决策里面得到奖励值，从而更新在各种状态下各种决策的Q值。这样，通过学习之后的模型变得很厉害，因为它清楚每一步决策的收益是多少，它会选择最有利的决策。

### 探索 vs 利用

这是强化学习的经典难题。

- 利用：一直选当前最优解。
- 探索：偶尔随机选，看看有没有更好的路。

最常用的是 ε-贪心策略：以 ε 的概率探索，其余时候利用。比如 ε=0.1，就代表 10% 的时候随便走走看。

拿Nim游戏举例：刚开始 AI 完全瞎走，经常输。随着奖励的积累，它会越来越聪明，最后几乎不会输。

> 课后作业有Nim游戏的核心算法实现

------

## 📊 无监督学习

无监督学习没有标签，模型只能自己从数据中找规律。

### 聚类 (Clustering)

最常见的任务就是聚类，把相似的数据点放到一起。应用很多，比如基因分组、图像分割。

### k-means聚类算法

1. 随机选 k 个中心点；
2. 把每个数据点分到最近的中心；
3. 更新中心点为组内均值；
4. 重复直到稳定。

最后就得到自然分组。

------

# 总结

这一讲的核心内容是：

- 监督学习：有标签 → 分类、回归
- 无监督学习：无标签 → 聚类
- 强化学习：靠奖励和惩罚学策略
- 模型常见问题：过拟合，用正则化和交叉验证来解决
- 实际工具：scikit-learn 提供了快速切换的算法

体会：

分类决定“是什么”，回归回答“是多少”，强化学习解决“怎么做”，无监督学习就是“自己发现规律”。
