# CS50 AI å­¦ä¹ ç¬”è®°ï¼šShopping ä½œä¸šæ€»ç»“

è¿™ä¸€è¯¾ç¬¬ä¸€ä¸ªä½œä¸šæ˜¯ **Shopping**ï¼Œç›®æ ‡æ˜¯å†™ä¸€ä¸ª AIï¼Œé¢„æµ‹ç”¨æˆ·åœ¨ç½‘ä¸Šè´­ç‰©æ—¶æ˜¯å¦ä¼šå®Œæˆè´­ä¹°ã€‚

------

## ğŸ“– é¢˜ç›®ç†è§£

é¢˜ç›®èƒŒæ™¯ï¼š
 åœ¨ç”µå•†ç½‘ç«™ä¸Šï¼Œå¤§éƒ¨åˆ†ç”¨æˆ·æµè§ˆæ—¶å¹¶ä¸ä¼šä¸‹å•ï¼Œä½†å¦‚æœæˆ‘ä»¬èƒ½é¢„æµ‹ç”¨æˆ·æ˜¯å¦æœ‰è´­ä¹°æ„å›¾ï¼Œå°±èƒ½é‡‡å–ä¸åŒç­–ç•¥ï¼Œæ¯”å¦‚ï¼šå¦‚æœé¢„æµ‹ç”¨æˆ·å¯èƒ½ä¸ä¼šä¹°ï¼Œå°±ç»™ç‚¹ä¼˜æƒ åˆ¸ã€‚

äºæ˜¯ä»»åŠ¡å°±å˜æˆäº†ï¼š

- è¾“å…¥ï¼šç”¨æˆ·çš„æµè§ˆè¡Œä¸ºï¼ˆè®¿é—®äº†å¤šå°‘é¡µé¢ã€åœç•™æ—¶é—´ã€æ˜¯å¦å‘¨æœ«ã€ç”¨ä»€ä¹ˆæµè§ˆå™¨ç­‰ç­‰ï¼‰
- è¾“å‡ºï¼šç”¨æˆ·æ˜¯å¦ä¼šä¸‹å•ï¼ˆ1 = ä¹°ï¼Œ0 = ä¸ä¹°ï¼‰

è®­ç»ƒæ•°æ®æœ‰å¤§çº¦ 12,000 ä¸ªç”¨æˆ·ä¼šè¯ã€‚æˆ‘ä»¬è¦åšçš„å°±æ˜¯è®­ç»ƒä¸€ä¸ª**æœ€è¿‘é‚»åˆ†ç±»å™¨ï¼ˆkNN, k=1ï¼‰**ï¼Œç„¶åç”¨å®ƒæ¥é¢„æµ‹ã€‚

------

## ğŸ› ï¸ è§£é¢˜æ€è·¯

è¿™ä¸ªä½œä¸šç›¸å¯¹æ¯”è¾ƒç®€å•ï¼Œä¸»è¦å°±æ˜¯å¯¹scikit-learnåº“çš„åˆæ­¥ç†Ÿæ‚‰ã€‚scikit-learnåº“çš„ç®€å•åº”ç”¨ï¼Œåœ¨è¯¾ç¨‹é‡Œé¢å·²ç»ç»™å‡ºäº†å…·ä½“çš„ä¾‹å­ï¼Œæœ¬æ¬¡ä½œä¸šç›¸å½“äºå°±æ˜¯ç…§è‘«èŠ¦ç”»ç“¢ã€‚

ä½œä¸šè¦æ±‚å®ç°ä¸‰ä¸ªå‡½æ•°ï¼š

### 1. `load_data(filename)`

- ä» CSV æ–‡ä»¶ä¸­è¯»å…¥æ•°æ®ã€‚
- `evidence`ï¼šæ¯ä¸ªç”¨æˆ·çš„ç‰¹å¾ï¼ˆ17 ä¸ªå€¼ï¼‰ã€‚
- `labels`ï¼šå¯¹åº”çš„è´­ä¹°ç»“æœï¼ˆ0 æˆ– 1ï¼‰ã€‚
- è¿”å›ä¸€ä¸ªtuple`ï¼ˆevidence, labelsï¼‰`
- éœ€è¦ç‰¹åˆ«æ³¨æ„**æ•°æ®ç±»å‹è½¬æ¢**ï¼šå“ªäº›æ˜¯ `int`ï¼Œå“ªäº›æ˜¯ `float`ï¼Œè¿˜æœ‰ `Month` è¦è½¬æˆ 0~11ï¼Œ`VisitorType` å’Œ `Weekend` è¦è½¬æˆ 0/1ã€‚

### 2. `train_model(evidence, labels)`

- ä½¿ç”¨ scikit-learn çš„ `KNeighborsClassifier`ï¼Œå‚æ•° `n_neighbors=1`ã€‚
- è°ƒç”¨ `.fit(evidence, labels)` æ¥è®­ç»ƒã€‚

### 3. `evaluate(labels, predictions)`

- è®¡ç®— **æ•æ„Ÿåº¦ (sensitivity)** = çœŸæ­£ä¾‹ç‡ = æ­£æ ·æœ¬é‡Œé¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹ã€‚
- è®¡ç®— **ç‰¹å¼‚åº¦ (specificity)** = çœŸè´Ÿä¾‹ç‡ = è´Ÿæ ·æœ¬é‡Œé¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹ã€‚
- è¿”å› `(sensitivity, specificity)`ã€‚

æœ€ç»ˆè¿è¡Œæ—¶ï¼Œè¾“å‡ºç»“æœç±»ä¼¼ï¼š

```
Correct: 4088
Incorrect: 844
True Positive Rate: 41.02%
True Negative Rate: 90.55%
```

------

## ğŸ“ä»£ç å®ç°

> æˆ‘è§‰å¾—æ²¡å¤ªå¤šè¯´çš„ï¼Œä»£ç æ¯”è¾ƒç®€å•ã€‚è¯¾ç¨‹é‡Œé¢å¦å¤–ä»‹ç»äº†å‡ ç§æ¨¡å‹ï¼Œå¯ä»¥ç›´æ¥å°è¯•åˆ‡æ¢æ¨¡å‹çœ‹çœ‹é¢„æµ‹ç»“æœçš„å˜åŒ–ã€‚

```python
import csv
import sys

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

TEST_SIZE = 0.4

def main():

    # Check command-line arguments
    if len(sys.argv) != 2:
        sys.exit("Usage: python shopping.py data")

    # Load data from spreadsheet and split into train and test sets
    evidence, labels = load_data(sys.argv[1])
    X_train, X_test, y_train, y_test = train_test_split(
        evidence, labels, test_size=TEST_SIZE
    )

    # Train model and make predictions
    model = train_model(X_train, y_train)
    predictions = model.predict(X_test)
    sensitivity, specificity = evaluate(y_test, predictions)

    # Print results
    print(f"Correct: {(y_test == predictions).sum()}")
    print(f"Incorrect: {(y_test != predictions).sum()}")
    print(f"True Positive Rate: {100 * sensitivity:.2f}%")
    print(f"True Negative Rate: {100 * specificity:.2f}%")


def load_data(filename):
    """
    Load shopping data from a CSV file `filename` and convert into a list of
    evidence lists and a list of labels. Return a tuple (evidence, labels).

    evidence should be a list of lists, where each list contains the
    following values, in order:
        - Administrative, an integer
        - Administrative_Duration, a floating point number
        - Informational, an integer
        - Informational_Duration, a floating point number
        - ProductRelated, an integer
        - ProductRelated_Duration, a floating point number
        - BounceRates, a floating point number
        - ExitRates, a floating point number
        - PageValues, a floating point number
        - SpecialDay, a floating point number
        - Month, an index from 0 (January) to 11 (December)
        - OperatingSystems, an integer
        - Browser, an integer
        - Region, an integer
        - TrafficType, an integer
        - VisitorType, an integer 0 (not returning) or 1 (returning)
        - Weekend, an integer 0 (if false) or 1 (if true)

    labels should be the corresponding list of labels, where each label
    is 1 if Revenue is true, and 0 otherwise.
    """
    evidence = []
    labels = []
    month = {"Jan": 0, "Feb": 1, "Mar": 2, "Apr": 3, "May": 4,"June": 5,
             "Jul": 6, "Aug": 7, "Sep": 8, "Oct": 9, "Nov": 10, "Dec": 11}

    with open(filename) as f:
        reader = csv.reader(f)
        next(reader)

        for row in reader:
            evidence.append([
                int(row[0]),
                float(row[1]),
                int(row[2]),
                float(row[3]),
                int(row[4]),
                float(row[5]),
                float(row[6]),
                float(row[7]),
                float(row[8]),
                float(row[9]),
                int(month[row[10]]),
                int(row[11]),
                int(row[12]),
                int(row[13]),
                int(row[14]),
                1 if row[15] == "Returning_Visitor" else 0,
                1 if row[16] == "TRUE" else 0
            ])
            labels.append(1 if row[-1] == "TRUE" else 0)
    
    return (evidence, labels)


def train_model(evidence, labels):
    """
    Given a list of evidence lists and a list of labels, return a
    fitted k-nearest neighbor model (k=1) trained on the data.
    """
    # model = Perceptron()
	# model = svm.SVC()
	# model = GaussianNB()
    model = KNeighborsClassifier(n_neighbors=1)
    model.fit(evidence, labels)
    return model


def evaluate(labels, predictions):
    """
    Given a list of actual labels and a list of predicted labels,
    return a tuple (sensitivity, specificity).

    Assume each label is either a 1 (positive) or 0 (negative).

    `sensitivity` should be a floating-point value from 0 to 1
    representing the "true positive rate": the proportion of
    actual positive labels that were accurately identified.

    `specificity` should be a floating-point value from 0 to 1
    representing the "true negative rate": the proportion of
    actual negative labels that were accurately identified.
    """
    true_pos_count = 0
    true_neg_count = 0

    for v_label, v_pre in zip(labels, predictions):
        if v_label == v_pre:
            if v_label == 1:
                true_pos_count += 1
            elif v_label == 0:
                true_neg_count += 1

    sensitivity = true_pos_count/labels.count(1)
    specificity = true_neg_count/labels.count(0)

    return sensitivity, specificity


if __name__ == "__main__":
    main()

```



## âœ¨ æ”¶è·ä¸ä½“ä¼š

ç¬¬ä¸€æ¬¡å®è·µ scikit-learnï¼Œæ„Ÿå—åˆ° scikit-learn çš„æ–¹ä¾¿ï¼šåªè¦ç”¨ `.fit()` è®­ç»ƒæ•°æ®å’Œ `.predict()`å¯¹æ•°æ®åšé¢„æµ‹ï¼Œæ ¸å¿ƒéƒ¨åˆ†ä¸€è¡Œå°±èƒ½è§£å†³ã€‚åˆ‡æ¢æ¨¡å‹ä¹Ÿå¾ˆæ–¹ä¾¿ã€‚scikit-learnåº“é‡Œé¢è¿˜æœ‰ä¼—å¤šæ¨¡å‹å¯ä»¥æ·±å…¥æ¢ç´¢ã€‚

è¿™è®©æˆ‘ä½“ä¼šåˆ°ï¼Œæœºå™¨å­¦ä¹ çœŸæ­£éš¾çš„éƒ¨åˆ†å¾€å¾€ä¸æ˜¯â€œè°ƒåº“â€ï¼Œè€Œæ˜¯æ•°æ®å‡†å¤‡å’Œç»“æœåˆ†æã€‚